{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "principles_of_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwwaMoahOGzV3I9MjAYpvr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kang-narae/AI-DL-DA/blob/main/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/principles_of_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  학습, 한 번의 epoch 원리"
      ],
      "metadata": {
        "id": "uySQwJHnN_y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "u3Isqzfbo6op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-uqlDkANJID"
      },
      "outputs": [],
      "source": [
        "class add_graph:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def forward(self, x, y):\n",
        "    out = x + y\n",
        "    return out #더한값 내겠다고\n",
        "  def backward(self, dout):  #덧셈미분\n",
        "    dx= 1*dout             #x를 미분하면 1?\n",
        "    dy= 1*dout         #y를 미분해도 1 ... 거기에 dout 곱함.    ##dout은 어떻게 계산되는 거야 ??\n",
        "    return dx, dy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class mul_graph:\n",
        "  def __init__(self):\n",
        "    self.x= None\n",
        "    self.y= None\n",
        "  def forward(self, x, y):\n",
        "    self.x = x             #지역변수로 하면 사라지니까, 그렇게 되지 않도록 self에 변수로 저장해놓고  backward함수 때 호출해서 사용하겠다는 거.\n",
        "    self.y= y\n",
        "    out = x*y\n",
        "    return out #곱한 값 내겠다고\n",
        "  def backward(self, dout):\n",
        "    dx = self.y * dout          #곱하기를 x에 대해 미분하면 y가 됨\n",
        "    dy= self.x* dout            #곱하기를 y에 대해 미분하면 x가 된다.\n",
        "    return dx, dy\n",
        "\n",
        "\n",
        "    #체인룰?\n",
        "    "
      ],
      "metadata": {
        "id": "iT8WN5jpPp8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mse_graph:\n",
        "  def __init__(self):\n",
        "    self.loss= None\n",
        "    self.y = None  #예측값\n",
        "    self.t = None     #정답\n",
        "    self.x  = None #입력값\n",
        "  def forward(self, y, t):\n",
        "    self.t= t\n",
        "    self.y= y\n",
        "    self.loss = np.square(self.t - self.y).sum()/ self.t.shape[0]   #에러제곱의 평균. 개수로 나눈거니까\n",
        "    return self.loss\n",
        "  def backward(self, x, dout=1):   #미분할거임\n",
        "    data_size= self.t.shape[0]\n",
        "    dweight_mse = ((self.y - self.t)*x).sum()*2/ data_size      #mse를 가중치에 대해 미분. 즉 weight에 따른 mse의 기울기. \n",
        "    dbias_mse=   (self.y - self.t).sum()*2/ data_size           #mse를 bias에 대해 미분. 즉 bias에 따른 mse의 기울기.\n",
        "    return dweight_mse, dbias_mse"
      ],
      "metadata": {
        "id": "i7wRCDKvbEuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple= 100\n",
        "apple_num= 2\n",
        "orange= 150\n",
        "orange_num= 3\n",
        "tax= 1.1"
      ],
      "metadata": {
        "id": "-hGG8jazQNtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mul_apple_graph =mul_graph()   #mul_graph 객체 만듦\n",
        "mul_orange_graph= mul_graph()\n",
        "add_apple_orange_graph = add_graph()\n",
        "mul_tax_graph =mul_graph()\n"
      ],
      "metadata": {
        "id": "QIpRrtVkQYNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apple_price = mul_apple_graph.forward(apple, apple_num)   #mul 객체로 애플가격과 애플개수\n",
        "orange_price= mul_orange_graph.forward(orange, orange_num)  #mul 객체로 오렌지가격x개수\n",
        "all_price= add_apple_orange_graph.forward(apple_price, orange_price)  #add객체로 애플총가격+오렌지총가격\n",
        "total_price= mul_tax_graph.forward(all_price, tax) #mul 객체로 세금포함가격 곱 \n",
        "print(total_price)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbX8t1XtQz_u",
        "outputId": "0ed6e31e-8e21-457c-b494-4dd68c5a0e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "715.0000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mse mean square error    평균제곱오차\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dprice= 1   #맨끝단에 줄 미분값.  dtotalprice의미임.  dtotalprice는 상순데 상수 미분하면 0인데 0 주면 안되니까 1주는거임?\n",
        "\n",
        "dall_price, dtax = mul_tax_graph.backward(dprice)\n",
        "dapple_price, dorange_price= add_apple_orange_graph.backward(dall_price)  \n",
        "dorange, dorange_num = mul_orange_graph.backward(dorange_price)\n",
        "dapple, dapple_num = mul_apple_graph.backward(dapple_price)\n",
        "print('dApple', dapple)   #apple이 1만큼 증가하면 결과가 2.2만큼 증가한다는 거\n",
        "print('dApple_num', dapple_num)\n",
        "print('dOrange', dorange)\n",
        "print('dOrange_num', dorange_num)             #각각의 노드들이 1이 증가할때 결과값이 얼마나 증가하느냐. 각각의 노드값이 결과값에 미치는 영향의 크기. 그게 미분값이다.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHNfaSNHRbZ2",
        "outputId": "3d36fc09-13b1-4689-f350-ed6b93964da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dApple 2.2\n",
            "dApple_num 110.00000000000001\n",
            "dOrange 3.3000000000000003\n",
            "dOrange_num 165.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def celsius_to_fahrenheit(x):\n",
        "  return x*1.8+32\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "aaMvd3OFiQiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #발산할 가능성 소거 위해 learning rate를 준다. 데이터 범위는 0~1로 두고.\n",
        " \n",
        " \n",
        "data_C =  np.array(range(100))\n",
        "data_F= celsius_to_fahrenheit (data_C)\n",
        "scaled_data_C = data_C/100   #0~1사이의 입력값\n",
        "scaled_data_F= data_F/100    #그 입력값 넣은 결과값\n",
        "print(scaled_data_C)\n",
        "print(scaled_data_F)\n",
        "\n",
        "                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vMUzSAZpDMg",
        "outputId": "aebcdd04-abd6-4dba-9284-14d5dae796ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
            " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
            " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
            " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
            " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
            " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
            " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
            " 0.98 0.99]\n",
            "[0.32  0.338 0.356 0.374 0.392 0.41  0.428 0.446 0.464 0.482 0.5   0.518\n",
            " 0.536 0.554 0.572 0.59  0.608 0.626 0.644 0.662 0.68  0.698 0.716 0.734\n",
            " 0.752 0.77  0.788 0.806 0.824 0.842 0.86  0.878 0.896 0.914 0.932 0.95\n",
            " 0.968 0.986 1.004 1.022 1.04  1.058 1.076 1.094 1.112 1.13  1.148 1.166\n",
            " 1.184 1.202 1.22  1.238 1.256 1.274 1.292 1.31  1.328 1.346 1.364 1.382\n",
            " 1.4   1.418 1.436 1.454 1.472 1.49  1.508 1.526 1.544 1.562 1.58  1.598\n",
            " 1.616 1.634 1.652 1.67  1.688 1.706 1.724 1.742 1.76  1.778 1.796 1.814\n",
            " 1.832 1.85  1.868 1.886 1.904 1.922 1.94  1.958 1.976 1.994 2.012 2.03\n",
            " 2.048 2.066 2.084 2.102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#맨 처음 만들어진 모델\n",
        "\n",
        "weight= np.random.uniform(0, 5, 1)   #0부터5사이의 값 랜덤하게 1개\n",
        "print(weight)\n",
        "bias= 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n2pT94Lp0A2",
        "outputId": "514f959c-ba50-4a31-f048-60043bc2490c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.46232119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight_graph= mul_graph()\n",
        "bias_graph= add_graph()\n",
        "\n",
        "\n",
        "weighted_data= weight_graph.forward(\n",
        "    weight, scaled_data_C\n",
        ")  #0~5사이의 가중치 x 0~1사이의 입력값 곱한 값. = 편향 더하기 전의 출력값\n",
        "\n",
        "predict_data = bias_graph.forward(\n",
        "    weighted_data, bias\n",
        ")  # 편향 더한 출력값 즉 예측값\n",
        "print(predict_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mt2LVRjqE0m",
        "outputId": "385b4ae2-d09e-4061-a5ce-581d7b46c252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.018443   0.036886   0.05532901 0.07377201 0.09221501\n",
            " 0.11065801 0.12910101 0.14754402 0.16598702 0.18443002 0.20287302\n",
            " 0.22131602 0.23975903 0.25820203 0.27664503 0.29508803 0.31353103\n",
            " 0.33197404 0.35041704 0.36886004 0.38730304 0.40574604 0.42418905\n",
            " 0.44263205 0.46107505 0.47951805 0.49796105 0.51640406 0.53484706\n",
            " 0.55329006 0.57173306 0.59017606 0.60861907 0.62706207 0.64550507\n",
            " 0.66394807 0.68239107 0.70083408 0.71927708 0.73772008 0.75616308\n",
            " 0.77460608 0.79304909 0.81149209 0.82993509 0.84837809 0.86682109\n",
            " 0.8852641  0.9037071  0.9221501  0.9405931  0.9590361  0.97747911\n",
            " 0.99592211 1.01436511 1.03280811 1.05125111 1.06969412 1.08813712\n",
            " 1.10658012 1.12502312 1.14346612 1.16190913 1.18035213 1.19879513\n",
            " 1.21723813 1.23568113 1.25412414 1.27256714 1.29101014 1.30945314\n",
            " 1.32789614 1.34633915 1.36478215 1.38322515 1.40166815 1.42011115\n",
            " 1.43855416 1.45699716 1.47544016 1.49388316 1.51232616 1.53076917\n",
            " 1.54921217 1.56765517 1.58609817 1.60454117 1.62298418 1.64142718\n",
            " 1.65987018 1.67831318 1.69675618 1.71519919 1.73364219 1.75208519\n",
            " 1.77052819 1.78897119 1.8074142  1.8258572 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이부분 잘이해안감\n",
        "\n",
        "\n",
        "dout= 1\n",
        "dbias, dbiased_data = bias_graph.backward(dout)   #미분은 뒤에서부터 백워드함수 더함. 처음에는 dout에 1주고\n",
        "#bias_Graph는 add 객체임. \n",
        "#편향값에 대한 미분과, 편향값 더한데이터에 대한 미분값\n",
        "dweight, dscaled_data_C= weight_graph.backward(\n",
        "    dbiased_data\n",
        ")  #biased_data에 대한 미분값\n",
        "print(dbias)   #x에대한 미분값 1개?\n",
        "print(dweight)  #weight에 대한 미분값 100개나옴. x를 100개 줬으니까 ?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeXiayT_rRPl",
        "outputId": "a6a3719d-d94c-4272-db3c-a96a5e993088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
            " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
            " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
            " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
            " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
            " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
            " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
            " 0.98 0.99]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mseGraph= mse_graph()\n",
        "mse= mseGraph.forward(predict_data, scaled_data_F)    \n",
        "print(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfsw5sdnruY9",
        "outputId": "adefb07c-1c5c-4b95-afca-acea20abaff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.089010085952557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vYE2NEOstjmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)\n",
        "print(weight_mse_gradient)\n",
        "print(bias_mse_gradient)\n",
        "  #mse의 weight에 대한 미분값. gradient는 기울기임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmX7dkAssMNF",
        "outputId": "f29adec3-5132-45c6-d0ea-316d1af50996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.2877080584378692\n",
            "-0.5961428016651295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "learned_weight = weight - learning_rate*weight_mse_gradient *np.average(dweight)\n",
        "print('before learning weight:', weight)\n",
        "print('after learning weight:', learned_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBIsCReZskG1",
        "outputId": "04845f7d-dde4-43aa-d08e-bdcc7dded4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before learning weight: [1.8443002]\n",
            "after learning weight: [1.85854175]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learned_bias = bias - learning_rate * bias_mse_gradient * dbias\n",
        "print('before learning bias:', bias)\n",
        "print('after learning bias:', learned_bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WemhXuUxtebW",
        "outputId": "ae313755-fb24-4018-e487-6af5297e87d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before learning bias: 0\n",
            "after learning bias: 0.05961428016651295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 원리 정리"
      ],
      "metadata": {
        "id": "FVjkBbM0Igv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dout=1\n",
        "learning_rate= 0.1\n",
        "error_list= []\n",
        "weight= np.random.uniform(0, 5, 1)   #0부터5사이의 값 랜덤하게 1개. 처음엔 틀린값이지. 랜덤weight였으니까.\n",
        "bias= 0\n",
        "\n",
        "for i in range(1000):\n",
        "\n",
        "#forward로 계산하고\n",
        "  weighted_data= weight_graph.forward(\n",
        "    weight, scaled_data_C)  \n",
        "  #scaled_Data_C(0~1사이의 입력값)에 wieght 곱해서  weightd_data가 되고\n",
        "\n",
        "  predict_data = bias_graph.forward(\n",
        "    weighted_data, bias)\n",
        "  #wighted_data에 bias 더해서 predict_Data가 된다\n",
        "\n",
        "  #backward로 미분값\n",
        "  dout= 1\n",
        "  dbias, dbiased_data = bias_graph.backward(dout)   #미분은 뒤에서부터 백워드함수 더함. 처음에는 dout에 1주고 . dbias의 미분값은 어차피 1이고.\n",
        "                                                  #bias의 미분값, biased_data의 미분값 구해서 \n",
        "  dweight, dscaled_data_C= weight_graph.backward(               #biased_data의 미분값을 이용해서  dweight,즉 weight의 미분값을 구한다. \n",
        "                                                 #dweight, weight의 미분값은 100개 나옴.\n",
        "    dbiased_data)\n",
        "  #mse\n",
        "  mse= mseGraph.forward(predict_data, scaled_data_F)    #mse를 구하고 미분을 해야함.예측값과 실제값을 인자로 받아서 에러loss손실을 출력해낸 게 mse.\n",
        "  error_list.append(mse)\n",
        "  weight_mse_gradient, bias_mse_gradient = mseGraph.backward(scaled_data_C)  #weight의 따른 mse의 기울기 즉 weight에 대한 mse의 미분값, 그리고 bias에 대한 mse의 미분값\n",
        "                      # x값에 scaled_Data_C넣어서 mse를 미분함.  mse를 weight에 대해 미분한  값과 mse를 bias에 대한 미분값을 구한다.\n",
        "  \n",
        "  #learning\n",
        "  learning_rate = 0.1\n",
        "  weight = weight - learning_rate*weight_mse_gradient *np.average(dweight)    #이전꺼 weight계속 수정해가는 거.\n",
        "                                                            #근데 왜 weight미분값(기울기)에다가 dweight의 미분값을 곱하지? dweight의 가중치를 곱해줘야하기때문!\n",
        "                                                            #weight_mse_gradient와 dweight의 차이가 뭐지?\n",
        "  bias = bias - learning_rate * bias_mse_gradient * dbias   #bias 계속 수정. 여기도 마찬가지로 미분값(가중치)를 곱해서 빼준다.\n",
        "                                                #여기도 마찬가지로 bias_mse_Gradient와 dbias의 차이가 뭐지?\n",
        "print(weight)\n",
        "print(bias)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn1VqT9Bt6nu",
        "outputId": "d401350f-8cf1-47c1-ccea-621572c7c282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.79917396]\n",
            "0.3204244377457187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "처음엔 틀린값이지. 랜덤weight였으니까.\n",
        "\n",
        "\n",
        "\n",
        "일단 미분을 해.\n",
        "뒤에서부터 backward 뒤가 bias그래프니까ㅡ bias 백워드(미분)하고\n",
        "그다음 weight 미분할 때는 biased_data 미분값이 필요하지. 덧셈그래프에서 나온 미분값이\n",
        "곱해져야하니까. dbiased_data를 곱해준 거임. (뭐에?)\n",
        "그래서 bias의 미분값.이건 어차피 1이고\n",
        "weigth에 대한 미분값은 100개 나오지 x니까 .  (< ??)\n",
        "\n",
        "이제 틀린 weight값을 수정해야해.\n",
        "랜덤하게 만들어서 틀린값이니까.\n",
        "정답에 가깝게 수정해야지.\n",
        "원래 미분값에서 mse의 미분값을 빼야함. 근데 그냥 빼면 발산할수있으니까\n",
        "learnig rate를 곱한다 (발산을 맊기 위해서.)\n",
        "\n",
        "그리고 wighte이랑 bias가 영향미치는게 다르니까 서로 다르게 빼줘야해\n",
        "wiehget수정할때는 그거의 미분값 곱해주고(가중치)\n",
        "bias수정할때는 그거의 미분값(가중치) 곱해서 빼줘야함.\n",
        "\n",
        "\n",
        "mse미분해야함. x값에 scaled_Data_C넣어서.\n",
        "그럼 mse를 weight에 대해 미분핱ㄴ 값과\n",
        "mse를 bias에 대한 미분값이 각각 나오지.\n",
        "\n",
        "그럼이제 weight부터 학습해보자고.\n",
        "원래 wiehgt에서 learnig rate랑 , mse를 weight에 대해서 미분한 값이랑, dweigth백개니까 평균낸 값 \n",
        "검색해서 그래프에서 빼줌.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "이게 한 epoch임.'''\n"
      ],
      "metadata": {
        "id": "YsJCY2Un1t67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(error_list[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5yvNpPv2Qdc",
        "outputId": "84835f36-3ff6-4815-e38c-d8febca2fa0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.794366527852133e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(error_list)\n",
        "plt.show()\n",
        "\n",
        "#러닝rate가 너무 작으면 기울기이동이 작아지니까 같은epoch면 근접값에 가기가 어려워질 수 있음.\n",
        "#그렇다고 learning rate 너무 크면 발산 위험있고."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "oJkSC9tJ2S9y",
        "outputId": "a1b7b4e1-c69c-4a23-8071-e8c0c6796971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AzbojsqQ2YxS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}